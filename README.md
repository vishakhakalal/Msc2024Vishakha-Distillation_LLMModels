# Msc2024Vishakha-Distillation_LLMModels
Data contamination and Data leakage in LLM distilled models

This project investigates the impact of data contamination and data leakage on the performance of distilled large language models (LLMs) in re-ranking scenarios. By exploring various BERT-based architectures, the study aims to uncover how these issues affect model generalization, accuracy, and reliability.
